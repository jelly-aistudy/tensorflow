import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

## DATA LOAD ##
_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'
path_to_zip = tf.keras.utils.get_file('cats_and_dogs_zip', origin=_URL, extract=True)  # Downloads a file from a URL if it not already in the cache.
PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered') # join directory or file names

train_dir = os.path.join(PATH, 'train')
valid_dir = os.path.join(PATH, 'validation')
train_cats_dir = os.path.join(train_dir, 'cats')
train_dogs_dir = os.path.join(train_dir, 'dogs')
valid_cats_dir = os.path.join(valid_dir, 'cats')
valid_dogs_dir = os.path.join(valid_dir, 'dogs')

num_cats_train = len(os.listdir(train_cats_dir))
num_dogs_train = len(os.listdir(train_dogs_dir))
num_cats_valid = len(os.listdir(valid_cats_dir))
num_dogs_valid = len(os.listdir(valid_dogs_dir))

total_train = num_cats_train + num_dogs_train
total_valid = num_cats_valid + num_dogs_valid

print('number of train cat images : ', num_cats_train)
print('number of train dog images : ', num_dogs_train)
print('number of validation cat images : ', num_cats_valid)
print('number of validation dog images : ', num_dogs_valid)

print('number of total train images : ', total_train)
print('number of total validation images : ', total_valid)

## IMAGE PREPROCESS ##
BATCH_SIZE = 128
IMG_HEIGHT = 150
IMG_WIDTH = 150

train_image_generator = ImageDataGenerator(rescale=1./255)
valid_image_generator = ImageDataGenerator(rescale=1./255)

train_data_gen = train_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')

valid_data_gen = valid_image_generator.flow_from_directory(batch_size=BATCH_SIZE,
                                                           directory=valid_dir,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')
                                                           
sample_train_image, sample_train_label = next(train_data_gen)
def plotSample(image_array):
  fig, axes = plt.subplots(1, 5, figsize=(20,20))
  axes = axes.flatten()
  for img, ax in zip(image_array, axes):
    ax.imshow(img)
    ax.axis('off')
  plt.tight_layout()
  plt.show()
  
plotSample(sample_train_image[:5])
print(sample_train_label[:5])
print(sample_train_image[0].shape)

## BATCH CALLBACK ##
class CollectBatchStats(tf.keras.callbacks.Callback):
  def __init__(self):
    self.batch_loss = []
    self.batch_accuracy = []
  
  def on_train_batch_end(self, batch, logs=None):
    self.batch_loss.append(logs['loss'])
    self.batch_accuracy.append(logs['acc'])
    self.model.reset_metrics()

## VGG TRANSFER ##
feature_extractor_vgg = tf.keras.applications.VGG16(include_top=False)
feature_extractor_vgg.trainable = False
feature_extractor_vgg.summary()

model_vgg = tf.keras.Sequential([
                             feature_extractor_vgg,
                             tf.keras.layers.GlobalAveragePooling2D(),
                             tf.keras.layers.Dense(128, activation='relu'),
                             tf.keras.layers.Dense(1, activation='sigmoid')
])
model_vgg.summary()

model_vgg.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
steps_per_epoch = np.ceil( total_train / BATCH_SIZE )
validation_steps = np.ceil( total_valid / BATCH_SIZE )
batch_stats_callback = CollectBatchStats()
history = model_vgg.fit(train_data_gen, validation_data = valid_data_gen, epochs=5, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[batch_stats_callback])
# you can also use model.fit_generator

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_loss)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_accuracy)

## INCEPTION TRANSFER ##
feature_extractor_inception = tf.keras.applications.InceptionV3(include_top=False)
feature_extractor_inception.summary()
feature_extractor_inception.trainable = False

model_inception = tf.keras.Sequential([
                                       feature_extractor_inception,
                                       tf.keras.layers.GlobalAveragePooling2D(),
                                       tf.keras.layers.Dense(1, activation='sigmoid')
])
model_inception.summary()
model_inception.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
history = model_inception.fit(train_data_gen, validation_data = valid_data_gen, epochs=5, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[batch_stats_callback])

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_loss)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_accuracy)

## RESNET TRANSFER ##
feature_extractor_res = tf.keras.applications.ResNet50V2(include_top=False)
feature_extractor_res.summary()
feature_extractor_res.trainable = False

model_res = tf.keras.Sequential([
                                       feature_extractor_res,
                                       tf.keras.layers.GlobalAveragePooling2D(),
                                       tf.keras.layers.Dense(1, activation='sigmoid')
])

model_res.summary()

model_res.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
history = model_res.fit(train_data_gen, validation_data = valid_data_gen, epochs=5, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[batch_stats_callback])

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_loss)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_accuracy)

## MOBILENET TRANSFER ##
feature_extractor_mobile = tf.keras.applications.MobileNetV2(include_top=False)
feature_extractor_mobile.summary()
feature_extractor_mobile.trainable = False

model_mobile = tf.keras.Sequential([
                                       feature_extractor_mobile,
                                       tf.keras.layers.GlobalAveragePooling2D(),
                                       tf.keras.layers.Dense(1, activation='sigmoid')
])

model_mobile.summary()
model_mobile.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
history = model_mobile.fit(train_data_gen, validation_data = valid_data_gen, epochs=5, steps_per_epoch=steps_per_epoch, validation_steps=validation_steps, callbacks=[batch_stats_callback])

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_loss)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_accuracy)

## TEST ##
!wget -O dog_sample.jpg https://www.guidingeyes.org/wp-content/uploads/2020/01/1-1.jpg
!wget -O cat_sample.jpg https://www.rd.com/wp-content/uploads/2019/11/cat-10-e1573844975155-768x519.jpg

def prediction_keras(path, target_size):
  img_show = plt.imread(path)
  plt.imshow(img_show)
  tmp = tf.keras.preprocessing.image.load_img(path, target_size=target_size)
  tmp = tf.keras.preprocessing.image.img_to_array(tmp)
  tmp = tmp/255.
  tmp = np.expand_dims(tmp, axis=0)
  print(tmp.shape)
  return tmp
  
dog_input = prediction_keras('dog_sample.jpg', (150, 150))
print('dog image prediction rate (vgg) -> ', model_vgg.predict(dog_input))
print('dog image prediction rate (inception) -> ', model_inception.predict(dog_input))
print('dog image prediction rate (resnet) -> ', model_res.predict(dog_input))
print('dog image prediction rate (mobile) -> ', model_mobile.predict(dog_input))
# dog image prediction rate (vgg) ->  [[0.99993026]]
# dog image prediction rate (inception) ->  [[0.99880755]]
# dog image prediction rate (resnet) ->  [[0.99982435]]
# dog image prediction rate (mobile) ->  [[0.9999347]]

cat_input = prediction_keras('cat_sample.jpg', (150,150))
print('cat image prediction rate (vgg) -> ', model_vgg.predict(cat_input))
print('cat image prediction rate (inception) -> ', model_inception.predict(cat_input))
print('cat image prediction rate (resnet) -> ', model_res.predict(cat_input))
print('cat image prediction rate (mobile) -> ', model_mobile.predict(cat_input))
# cat image prediction rate (vgg) ->  [[0.00213277]]
# cat image prediction rate (inception) ->  [[0.00033831]]
# cat image prediction rate (resnet) ->  [[0.00046858]]
# cat image prediction rate (mobile) ->  [[0.00372232]]

model_name = 'catsndogs_model_vgg'
export_path = model_name
model_vgg.save(export_path, save_format='tf')
export_path
