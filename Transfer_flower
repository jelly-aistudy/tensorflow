import tensorflow as tf
import matplotlib.pylab as plt
import numpy as np
import PIL.Image as Image

IMAGE_SHAPE = (224,224)
flower_data = tf.keras.utils.get_file(
  'flower_photos','https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)

image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)
image_gen = image_generator.flow_from_directory(str(flower_data), batch_size=32, target_size=IMAGE_SHAPE)
print(plt.imshow(image_gen[0][0][0])) # see flower image

for image_batch, label_batch in image_gen:
  print("image batch shape: ", image_batch.shape) # (32,224,224,3) # batch size = 32
  print("label batch shape: ", label_batch.shape) # (32,5) 5 classes
  break

feature_extractor_layer = tf.keras.applications.MobileNetV2(include_top=False)
feature_batch = feature_extractor_layer(image_batch)
print(feature_batch) # (32, 7, 7, 1280)
print(image_gen.num_classes) # 5

feature_extractor_layer.trainable = False
model = tf.keras.Sequential([
  feature_extractor_layer,
  tf.keras.layers.GlobalAveragePooling2D(), # similar to Flatten
  tf.keras.layers.Dense(image_gen.num_classes, activation='softmax')
])

predictions = model(image_batch)
print(predictions.shape) # TensorShape([32,5])

model.compile(
  optimizer='adam',
  loss='categorical_crossentropy',
  metrics=['acc'])

class CollectBatchStats(tf.keras.callbacks.Callback): # loss and accuracy per batch
  def __init__(self):
    self.batch_losses = []
    self.batch_acc = []

  def on_train_batch_end(self, batch, logs=None):
    self.batch_losses.append(logs['loss'])
    self.batch_acc.append(logs['acc'])
    self.model.reset_metrics()
    
steps_per_epoch = np.ceil(image_gen.samples/image_gen.batch_size)
batch_stats_callback = CollectBatchStats()
history = model.fit(image_gen, epochs=2,
                              steps_per_epoch=steps_per_epoch,
                              callbacks = [batch_stats_callback], verbose=1)
                              
plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_losses)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_acc)

class_names = sorted(image_gen.class_indices.items(), key=lambda pair:pair[1])
# image_gen.class_indices : {'daisy': 0, 'dandelion': 1, 'roses': 2, 'sunflowers': 3, 'tulips': 4}
# class_names : 
# [('daisy', 0),
# ('dandelion', 1),
# ('roses', 2),
# ('sunflowers', 3),
# ('tulips', 4)]
class_names = np.array([key.title() for key, value in class_names])
print(class_names) # array(['Daisy', 'Dandelion', 'Roses', 'Sunflowers', 'Tulips'], dtype='<U10')

predicted_batch = model.predict(image_batch)
predicted_id = np.argmax(predicted_batch, axis=-1)
predicted_label_batch = class_names[predicted_id]
true_label_id = np.argmax(label_batch, axis=-1)

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(image_batch[n])
  color = "green" if predicted_id[n] == true_label_id[n] else "red"
  plt.title(predicted_label_batch[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

model_name = 'transfer_flower'
export_path = "/tmp/saved_models/"+model_name
model.save(export_path, save_format='tf')
export_path

reloaded = tf.keras.models.load_model(export_path)
result_batch = model.predict(image_batch)
reloaded_result_batch = reloaded.predict(image_batch)
abs(reloaded_result_batch - result_batch).max() # 0.0
