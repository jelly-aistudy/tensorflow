import json
import tensorflow as tf
import numpy as np
import urllib
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import Dense, Embedding, LSTM, Bidirectional
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping

url = 'https://storage.googleapis.com/download.tensorflow.org/data/sarcasm.json'
urllib.request.urlretrieve(url, 'sarcasm.json')

vocab_size = 1000
embedding_dim = 16
max_length = 120
trunc_type='post'
padding_type='post'
oov_tok = "<OOV>"
training_size = 20000

sentences = []
labels = []

with open('sarcasm.json') as f:
    datas = json.load(f)
    
for data in datas:
   sentences.append(data['headline'])
   labels.append(data['is_sarcastic'])
    
train_sentence = sentences[:training_size]
train_label = labels[:training_size]
valid_sentence = sentences[training_size:]
valid_label = labels[training_size:]

tokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_tok)
tokenizer.fit_on_texts(train_sentence)

train_sequence = tokenizer.texts_to_sequences(train_sentence)
valid_sequence = tokenizer.texts_to_sequences(valid_sentence)
train_padded = pad_sequences(train_sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)
valid_padded = pad_sequences(valid_sequence, maxlen=max_length, padding=padding_type, truncating=trunc_type)
train_label = np.array(train_label)
valid_label = np.array(valid_label)

model = Sequential([
     Embedding(vocab_size, embedding_dim, input_length=max_length),
     Bidirectional(LSTM(64, return_sequences=True)),
     Bidirectional(LSTM(64, return_sequences=True)),
     Bidirectional(LSTM(128)),
     Dense(64, activation='relu'),
     Dense(32, activation='relu'),
     Dense(1, activation='sigmoid')
])

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])

ckpath = 'jelly.ckpt'
checkpoint = ModelCheckpoint(filepath=ckpath,
                             save_best_only=True,
                             save_weights_only=True,
                             monitor='val_loss',
                             verbose=1)
    
earlystop = EarlyStopping(monitor='val_loss', patience=5)

model.fit(train_padded, train_label, 
          validation_data=(valid_padded, valid_label),
          epochs=20,
          callbacks=[checkpoint, earlystop])
    
model.load_weights(ckpath)
